{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8PJckg0Ff4jcg04UeeOaa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/naga-dheeraj-p/Assignments/blob/main/Quant_Analyst_Internship.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install dask"
      ],
      "metadata": {
        "id": "-ZoIgiTrzO7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1baaa501-7212-4d30-d3db-b71390d6da6e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask in /usr/local/lib/python3.10/dist-packages (2023.8.1)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from dask) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask) (24.0)\n",
            "Requirement already satisfied: partd>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from dask) (1.4.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask) (6.0.1)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask) (3.18.1)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.2.0->dask) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHdfOennBYES",
        "outputId": "487cc03f-42b8-4ad6-d1b1-827b24b4d547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "sql_engine = create_engine(\"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\")\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "tables_query = '''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%';\n",
        "'''\n",
        "\n",
        "tables_df = pd.read_sql_query(tables_query, sql_engine)\n",
        "\n",
        "tables_ddf = dd.from_pandas(tables_df, npartitions=1)\n",
        "relevant_table_names = tables_ddf[tables_ddf['name'].str[-4:].astype(int) > 2017]['name'].compute().tolist()\n",
        "\n",
        "count = len(relevant_table_names)\n",
        "\n",
        "print(\"Relevant Table Names:\")\n",
        "print(relevant_table_names)\n",
        "print(\"Count of trading days from 2018 onwards:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tcrNJZYHGriR",
        "outputId": "51498e4a-5b98-4f58-8526-403e7d5e0f9b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevant Table Names:\n",
            "['01012018', '02012018', '03012018', '04012018', '05012018', '08012018', '09012018', '10012018', '11012018', '12012018', '15012018', '16012018', '17012018', '18012018', '19012018', '22012018', '23012018', '24012018', '25012018', '29012018', '30012018', '31012018', '01022018', '02022018', '05022018', '06022018', '07022018', '08022018', '09022018', '12022018', '14022018', '15022018', '16022018', '19022018', '20022018', '21022018', '22022018', '23022018', '26022018', '27022018', '28022018', '01032018', '05032018', '06032018', '07032018', '08032018', '09032018', '12032018', '13032018', '14032018', '15032018', '16032018', '19032018', '20032018', '21032018', '22032018', '23032018', '26032018', '27032018', '28032018', '02042018', '03042018', '04042018', '05042018', '06042018', '09042018', '10042018', '11042018', '12042018', '13042018', '16042018', '17042018', '18042018', '19042018', '20042018', '23042018', '24042018', '25042018', '26042018', '27042018', '30042018', '02052018', '03052018', '04052018', '07052018', '08052018', '09052018', '10052018', '11052018', '14052018', '15052018', '16052018', '17052018', '18052018', '21052018', '22052018', '23052018', '24052018', '25052018', '28052018', '29052018', '30052018', '31052018', '01062018', '04062018', '05062018', '06062018', '07062018', '08062018', '11062018', '12062018', '13062018', '14062018', '15062018', '18062018', '19062018', '20062018', '21062018', '22062018', '25062018', '26062018', '27062018', '28062018', '29062018', '02072018', '03072018', '04072018', '05072018', '06072018', '09072018', '10072018', '11072018', '12072018', '13072018', '16072018', '17072018', '18072018', '19072018', '20072018', '23072018', '24072018', '25072018', '26072018', '27072018', '30072018', '31072018', '01082018', '02082018', '03082018', '06082018', '07082018', '08082018', '09082018', '10082018', '13082018', '14082018', '16082018', '17082018', '20082018', '21082018', '23082018', '24082018', '27082018', '28082018', '29082018', '30082018', '31082018', '03092018', '04092018', '05092018', '06092018', '07092018', '10092018', '11092018', '12092018', '14092018', '17092018', '18092018', '19092018', '21092018', '24092018', '25092018', '26092018', '27092018', '28092018', '01102018', '03102018', '04102018', '05102018', '08102018', '09102018', '10102018', '11102018', '12102018', '15102018', '16102018', '17102018', '19102018', '22102018', '23102018', '24102018', '25102018', '26102018', '29102018', '30102018', '31102018', '01112018', '02112018', '05112018', '06112018', '07112018', '09112018', '12112018', '13112018', '14112018', '15112018', '16112018', '19112018', '20112018', '21112018', '22112018', '26112018', '27112018', '28112018', '29112018', '30112018', '03122018', '04122018', '05122018', '06122018', '07122018', '10122018', '11122018', '12122018', '13122018', '14122018', '17122018', '18122018', '19122018', '20122018', '21122018', '24122018', '26122018', '27122018', '28122018', '31122018', '01012019', '02012019', '03012019', '04012019', '07012019', '08012019', '09012019', '10012019', '11012019', '14012019', '15012019', '16012019', '17012019', '18012019', '21012019', '22012019', '23012019', '24012019', '25012019', '28012019', '29012019', '30012019', '31012019', '01022019', '04022019', '05022019', '06022019', '07022019', '08022019', '11022019', '12022019', '13022019', '14022019', '15022019', '18022019', '19022019', '20022019', '21022019', '22022019', '25022019', '26022019', '27022019', '28022019', '01032019', '05032019', '06032019', '07032019', '08032019', '11032019', '12032019', '13032019', '14032019', '15032019', '18032019', '19032019', '20032019', '22032019', '25032019', '26032019', '27032019', '28032019', '29032019', '01042019', '02042019', '03042019', '04042019', '05042019', '08042019', '09042019', '10042019', '11042019', '12042019', '15042019', '16042019', '18042019', '22042019', '23042019', '24042019', '25042019', '26042019', '30042019', '02052019', '03052019', '06052019', '07052019', '08052019', '09052019', '10052019', '13052019', '14052019', '15052019', '16052019', '17052019', '20052019', '21052019', '22052019', '23052019', '24052019', '27052019', '28052019', '29052019', '30052019', '31052019', '03062019', '04062019', '06062019', '07062019', '10062019', '11062019', '12062019', '13062019', '14062019', '17062019', '18062019', '19062019', '20062019', '21062019', '24062019', '25062019', '26062019', '27062019', '28062019', '01072019', '02072019', '03072019', '04072019', '05072019', '08072019', '09072019', '10072019', '11072019', '12072019', '15072019', '16072019', '17072019', '18072019', '19072019', '22072019', '23072019', '24072019', '25072019', '26072019', '29072019', '30072019', '31072019', '01082019', '02082019', '05082019', '06082019', '07082019', '08082019', '09082019', '13082019', '14082019', '16082019', '19082019', '20082019', '21082019', '22082019', '23082019', '26082019', '27082019', '28082019', '29082019', '30082019', '03092019', '04092019', '05092019', '06092019', '09092019', '11092019', '12092019', '13092019', '16092019', '17092019', '18092019', '19092019', '20092019', '23092019', '24092019', '25092019', '26092019', '27092019', '30092019', '01102019', '03102019', '04102019', '07102019', '09102019', '10102019', '11102019', '14102019', '15102019', '16102019', '17102019', '18102019', '22102019', '23102019', '24102019', '25102019', '27102019', '29102019', '30102019', '31102019', '01112019', '04112019', '05112019', '06112019', '07112019', '08112019', '11112019', '13112019', '14112019', '15112019', '18112019', '19112019', '20112019', '21112019', '22112019', '25112019', '26112019', '27112019', '28112019', '29112019', '02122019', '03122019', '04122019', '05122019', '06122019', '09122019', '10122019', '11122019', '12122019', '13122019', '16122019', '17122019', '18122019', '19122019', '20122019', '23122019', '24122019', '26122019', '27122019', '30122019', '31122019', '01012020', '02012020', '03012020', '06012020', '07012020', '08012020', '09012020', '10012020', '13012020', '14012020', '15012020', '16012020', '17012020', '20012020', '21012020', '22012020', '23012020', '24012020', '27012020', '28012020', '29012020', '30012020', '31012020', '01022020', '03022020', '04022020', '05022020', '06022020', '07022020', '10022020', '11022020', '12022020', '13022020', '14022020', '17022020', '18022020', '19022020', '20022020', '24022020', '25022020', '26022020', '27022020', '28022020', '02032020', '03032020', '04032020', '05032020', '06032020', '09032020', '11032020', '12032020', '13032020', '16032020', '17032020', '18032020', '19032020', '20032020', '23032020', '24032020', '25032020', '26032020', '27032020', '30032020', '31032020', '01042020', '03042020', '07042020', '08042020', '09042020', '13042020', '15042020', '16042020', '17042020', '20042020', '21042020', '22042020', '23042020', '24042020', '27042020', '28042020', '29042020', '30042020', '04052020', '05052020', '06052020', '07052020', '08052020', '11052020', '12052020', '13052020', '14052020', '15052020', '18052020', '19052020', '20052020', '21052020', '22052020', '26052020', '27052020', '28052020', '29052020', '01062020', '02062020', '03062020', '04062020', '05062020', '08062020', '09062020', '10062020', '11062020', '12062020', '15062020', '16062020', '17062020', '18062020', '19062020', '22062020', '23062020', '24062020', '25062020', '26062020', '29062020', '30062020', '01072020', '02072020', '03072020', '06072020', '07072020', '08072020', '09072020', '10072020', '13072020', '14072020', '15072020', '16072020', '17072020', '20072020', '21072020', '22072020', '23072020', '24072020', '27072020', '28072020', '29072020', '30072020', '31072020', '03082020', '04082020', '05082020', '06082020', '07082020', '10082020', '11082020', '12082020', '13082020', '14082020', '18082020', '19082020', '20082020', '21082020', '24082020', '25082020', '26082020', '27082020', '28082020', '31082020', '01092020', '02092020', '03092020', '04092020', '07092020', '08092020', '09092020', '10092020', '11092020', '14092020', '15092020', '16092020', '17092020', '18092020', '21092020', '22092020', '23092020', '24092020', '25092020', '28092020', '29092020', '30092020', '01102020', '05102020', '06102020', '07102020', '08102020', '09102020', '12102020', '13102020', '14102020', '15102020', '16102020', '19102020', '20102020', '21102020', '22102020', '23102020', '26102020', '27102020', '28102020', '29102020', '30102020', '02112020', '03112020', '04112020', '05112020', '06112020', '09112020', '10112020', '11112020', '12112020', '13112020', '14112020', '17112020', '18112020', '19112020', '20112020', '23112020', '24112020', '25112020', '26112020', '27112020', '01122020', '02122020', '03122020', '04122020', '07122020', '08122020', '09122020', '10122020', '11122020', '14122020', '15122020', '16122020', '17122020', '18122020', '21122020', '22122020', '23122020', '24122020', '28122020', '29122020', '30122020', '31122020', '01012021', '04012021', '05012021', '06012021', '07012021', '08012021', '11012021', '12012021', '13012021', '14012021', '15012021', '18012021', '19012021', '20012021', '21012021', '22012021', '25012021', '27012021', '28012021', '29012021', '01022021', '02022021', '03022021', '04022021', '05022021', '08022021', '09022021', '10022021', '11022021', '12022021', '15022021', '16022021', '17022021', '18022021', '19022021', '22022021', '23022021', '24022021', '25022021', '26022021', '01032021', '02032021', '03032021', '04032021', '05032021', '08032021', '09032021', '10032021', '12032021', '15032021', '16032021', '17032021', '18032021', '19032021', '22032021', '23032021', '24032021', '25032021', '26032021', '30032021', '31032021', '01042021', '05042021', '06042021', '07042021', '08042021', '09042021', '12042021', '13042021', '15042021', '16042021', '19042021', '20042021', '22042021', '23042021', '26042021', '27042021', '28042021', '29042021', '30042021', '03052021', '04052021', '05052021', '06052021', '07052021', '10052021', '11052021', '12052021', '14052021', '17052021', '18052021', '19052021', '20052021', '21052021', '24052021', '25052021', '26052021', '27052021', '28052021', '31052021', '01062021', '02062021', '03062021', '04062021', '07062021', '08062021', '09062021', '10062021', '11062021', '14062021', '15062021', '16062021', '17062021', '18062021', '21062021', '22062021', '23062021', '24062021', '25062021', '28062021', '29062021', '30062021', '01072021', '02072021', '05072021', '06072021', '07072021', '08072021', '09072021', '12072021', '13072021', '14072021', '15072021', '16072021', '19072021', '20072021', '22072021', '23072021', '26072021', '27072021', '28072021', '29072021', '30072021', '02082021', '03082021', '04082021', '05082021', '06082021', '09082021', '10082021', '11082021', '12082021', '13082021', '16082021', '17082021', '18082021', '20082021', '23082021', '24082021', '25082021', '26082021', '27082021', '30082021', '31082021', '01092021', '02092021', '03092021', '06092021', '07092021', '08092021', '09092021', '13092021', '14092021', '15092021', '16092021', '17092021', '20092021', '21092021', '22092021', '23092021', '24092021', '27092021', '28092021', '29092021', '30092021', '01102021', '04102021', '05102021', '06102021', '07102021', '08102021', '11102021', '12102021', '13102021', '14102021', '18102021', '19102021', '20102021', '21102021', '22102021', '25102021', '26102021', '27102021', '28102021', '29102021', '01112021', '02112021', '03112021', '08112021', '09112021', '10112021', '11112021', '12112021', '15112021', '16112021', '17112021', '18112021', '22112021', '23112021', '24112021', '25112021', '26112021', '29112021', '30112021', '01122021', '02122021', '03122021', '06122021', '07122021', '08122021', '09122021', '10122021', '13122021', '14122021', '15122021', '16122021', '17122021', '20122021', '21122021', '22122021', '23122021', '24122021', '27122021', '28122021', '29122021', '30122021', '31122021', '03012022', '04012022', '05012022', '06012022', '07012022', '10012022', '11012022', '12012022', '13012022', '14012022', '17012022', '18012022', '19012022', '20012022', '21012022', '24012022', '25012022', '27012022', '28012022', '31012022', '01022022', '02022022', '03022022', '04022022', '07022022', '08022022', '09022022', '10022022', '11022022', '14022022', '15022022', '16022022', '17022022', '18022022', '21022022', '22022022', '23022022', '25022022', '28022022', '02032022', '03032022', '04032022', '07032022', '08032022', '09032022', '10032022', '11032022', '14032022', '15032022', '16032022', '17032022', '21032022', '22032022', '23032022', '24032022', '25032022', '28032022', '29032022', '30032022', '31032022', '01042022', '04042022', '05042022', '06042022', '07042022', '08042022', '11042022', '12042022', '13042022', '18042022', '19042022', '20042022', '21042022', '22042022', '25042022', '26042022', '27042022', '28042022', '29042022', '02052022', '04052022', '05052022', '06052022', '09052022', '10052022', '11052022', '12052022', '13052022', '16052022', '17052022', '18052022', '19052022', '20052022', '23052022', '24052022', '25052022', '26052022', '27052022', '30052022', '31052022', '01062022', '02062022', '03062022', '06062022', '07062022', '08062022', '09062022', '10062022', '13062022', '14062022', '15062022', '16062022', '17062022', '20062022', '21062022', '22062022', '23062022', '24062022', '27062022', '28062022', '29062022', '30062022', '01072022', '04072022', '05072022', '06072022', '07072022', '08072022', '11072022', '12072022', '13072022', '14072022', '15072022', '18072022', '19072022', '20072022', '21072022', '22072022', '25072022', '26072022', '27072022', '28072022', '29072022', '01082022', '02082022', '03082022', '04082022', '05082022', '08082022', '10082022', '11082022', '12082022', '16082022', '17082022', '18082022', '19082022', '22082022', '23082022', '24082022', '26082022', '29082022', '30082022', '01092022', '02092022', '05092022', '06092022', '07092022', '08092022', '09092022', '12092022', '13092022', '14092022', '15092022', '16092022', '19092022', '20092022', '21092022', '22092022', '23092022', '26092022', '27092022', '28092022', '29092022', '30092022', '03102022', '04102022', '06102022', '07102022', '10102022', '11102022', '12102022', '13102022', '14102022', '17102022', '18102022', '19102022', '20102022', '21102022', '24102022', '25102022', '27102022', '28102022', '31102022', '01112022', '02112022', '03112022', '04112022', '07112022', '09112022', '10112022', '11112022', '14112022', '15112022', '16112022', '17112022', '18112022', '21112022', '22112022', '23112022', '24112022', '25112022', '28112022', '29112022', '30112022', '01122022', '02122022', '05122022', '06122022', '07122022', '08122022', '09122022', '12122022', '13122022', '14122022', '15122022', '16122022', '19122022', '20122022', '21122022', '22122022', '23122022', '26122022', '27122022', '28122022', '29122022', '30122022', '02012023', '03012023', '04012023', '05012023', '06012023', '09012023', '10012023', '11012023', '12012023', '13012023', '16012023', '17012023', '18012023', '19012023', '20012023', '23012023', '24012023', '25012023', '27012023', '30012023', '31012023', '02022023', '03022023', '06022023', '07022023', '08022023', '09022023', '10022023', '13022023', '14022023', '15022023', '16022023', '17022023', '20022023', '21022023', '22022023', '23022023', '24022023', '27022023', '28022023', '01032023', '02032023', '03032023', '06032023', '08032023', '09032023', '10032023', '13032023', '14032023', '15032023', '16032023', '17032023', '20032023', '21032023', '22032023', '23032023', '24032023', '27032023', '28032023', '29032023', '31032023', '03042023', '05042023', '06042023', '10042023', '11042023', '12042023', '13042023', '17042023', '18042023', '19042023', '20042023', '21042023', '24042023', '25042023', '26042023', '27042023', '28042023', '02052023', '03052023', '04052023', '05052023', '08052023', '09052023', '10052023', '11052023', '12052023', '15052023', '16052023', '17052023', '18052023', '19052023', '22052023', '23052023', '24052023', '25052023', '26052023', '29052023', '30052023', '31052023', '01062023', '02062023', '05062023', '06062023', '07062023', '08062023', '09062023', '12062023', '13062023', '14062023', '15062023', '16062023', '19062023', '20062023', '21062023', '22062023', '23062023', '26062023', '27062023', '28062023', '30062023', '03072023', '04072023', '05072023', '06072023', '07072023', '10072023', '11072023', '12072023', '13072023', '14072023', '17072023', '18072023', '19072023', '20072023', '21072023', '24072023', '25072023', '26072023', '27072023', '28072023', '31072023', '01082023', '02082023', '03082023', '04082023', '07082023', '08082023', '09082023', '10082023', '11082023', '14082023', '16082023', '17082023', '18082023', '21082023', '22082023', '23082023', '24082023', '25082023', '28082023', '29082023', '30082023', '31082023', '01092023', '04092023', '05092023', '06092023', '07092023', '08092023', '11092023', '12092023', '13092023', '14092023', '15092023', '18092023', '20092023', '21092023', '22092023', '25092023', '26092023', '27092023', '28092023', '29092023', '03102023', '04102023', '05102023', '06102023', '09102023', '10102023', '11102023', '12102023', '13102023', '16102023', '17102023', '18102023', '19102023', '20102023', '23102023', '25102023', '26102023', '27102023', '30102023', '31102023', '01112023', '02112023', '17082020', '01022023', '24022022', '25082022', '03112023', '06112023', '07112023', '08112023', '09112023', '10112023', '12112023', '13112023', '15112023', '16112023', '17112023', '20112023', '21112023', '22112023', '23112023', '24112023', '28112023', '29112023', '30112023', '01122023', '04122023', '05122023', '06122023', '07122023', '08122023', '11122023', '12122023', '13122023', '14122023', '15122023', '18122023', '19122023', '20122023', '21122023', '22122023', '26122023', '27122023', '28122023']\n",
            "Count of trading days from 2018 onwards: 1483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Read data from each table using Dask\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Create a select statement\n",
        "    select_stmt = select([table]).alias()\n",
        "    # Read data into Dask DataFrame\n",
        "    df_dask = dd.read_sql_table(select_stmt, connection_string, index_col='time', npartitions=4)\n",
        "    dfs.append(df_dask)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "7qGg1ghF5nhk",
        "outputId": "58d00a27-9b60-4e41-ab57-036b1f8c771e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ArgumentError",
          "evalue": "Column expression, FROM clause, or other columns clause element expected, got [Table('01012018', MetaData(), Column('time', TEXT(), table=<01012018>), Column('symbol', TEXT(), table=<01012018>), Column('open', REAL(), table=<01012018>), Column('high', REAL(), table=<01012018>), Column('low', REAL(), table=<01012018>), Column('close', REAL(), table=<01012018>), Column('volume', INTEGER(), table=<01012018>), Column('oi', INTEGER(), table=<01012018>), Column('expiry', TEXT(), table=<01012018>), Column('strike', INTEGER(), table=<01012018>), Column('instrument_type', TEXT(), table=<01012018>), schema=None)]. Did you mean to say select(Table('01012018', MetaData(), Column('time', TEXT(), table=<01012018>), Column('symbol', TEXT(), table=<01012018>), Column('open', REAL(), table=<01012018>), Column('high', REAL(), table=<01012018>), Column('low', REAL(), table=<01012018>), Column('close', REAL(), table=<01012018>), Column('volume', INTEGER(), table=<01012018>), Column('oi', INTEGER(), table=<01012018>), Column('expiry', TEXT(), table=<01012018>), Column('strike', INTEGER(), table=<01012018>), Column('instrument_type', TEXT(), table=<01012018>), schema=None))?",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-dd84e5c5c4d2>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoload_with\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;31m# Create a select statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mselect_stmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Read data into Dask DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdf_dask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_stmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/_selectable_constructors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(*entities, **__kw)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__kw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0m_no_kw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mSelect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/selectable.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *entities)\u001b[0m\n\u001b[1;32m   5129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m         \"\"\"\n\u001b[0;32m-> 5131\u001b[0;31m         self._raw_columns = [\n\u001b[0m\u001b[1;32m   5132\u001b[0m             coercions.expect(\n\u001b[1;32m   5133\u001b[0m                 \u001b[0mroles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumnsClauseRole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_propagate_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/selectable.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5130\u001b[0m         \"\"\"\n\u001b[1;32m   5131\u001b[0m         self._raw_columns = [\n\u001b[0;32m-> 5132\u001b[0;31m             coercions.expect(\n\u001b[0m\u001b[1;32m   5133\u001b[0m                 \u001b[0mroles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumnsClauseRole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_propagate_attrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5134\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/coercions.py\u001b[0m in \u001b[0;36mexpect\u001b[0;34m(role, element, apply_propagate_attrs, argname, post_inspect, disable_inspection, **kw)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mresolved\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                     resolved = impl._literal_coercion(\n\u001b[0m\u001b[1;32m    397\u001b[0m                         \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/coercions.py\u001b[0m in \u001b[0;36m_literal_coercion\u001b[0;34m(self, element, argname, **kw)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0melements\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumnClause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_literal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_for_expected\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/coercions.py\u001b[0m in \u001b[0;36m_raise_for_expected\u001b[0;34m(self, element, argname, resolved, advice, **kw)\u001b[0m\n\u001b[1;32m   1120\u001b[0m             )\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         return super()._raise_for_expected(\n\u001b[0m\u001b[1;32m   1123\u001b[0m             \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolved\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolved\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madvice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/coercions.py\u001b[0m in \u001b[0;36m_raise_for_expected\u001b[0;34m(self, element, argname, resolved, advice, code, err, **kw)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m         super()._raise_for_expected(\n\u001b[0m\u001b[1;32m    694\u001b[0m             \u001b[0melement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0margname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sqlalchemy/sql/coercions.py\u001b[0m in \u001b[0;36m_raise_for_expected\u001b[0;34m(self, element, argname, resolved, advice, code, err, **kw)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0madvice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mArgumentError\u001b[0m: Column expression, FROM clause, or other columns clause element expected, got [Table('01012018', MetaData(), Column('time', TEXT(), table=<01012018>), Column('symbol', TEXT(), table=<01012018>), Column('open', REAL(), table=<01012018>), Column('high', REAL(), table=<01012018>), Column('low', REAL(), table=<01012018>), Column('close', REAL(), table=<01012018>), Column('volume', INTEGER(), table=<01012018>), Column('oi', INTEGER(), table=<01012018>), Column('expiry', TEXT(), table=<01012018>), Column('strike', INTEGER(), table=<01012018>), Column('instrument_type', TEXT(), table=<01012018>), schema=None)]. Did you mean to say select(Table('01012018', MetaData(), Column('time', TEXT(), table=<01012018>), Column('symbol', TEXT(), table=<01012018>), Column('open', REAL(), table=<01012018>), Column('high', REAL(), table=<01012018>), Column('low', REAL(), table=<01012018>), Column('close', REAL(), table=<01012018>), Column('volume', INTEGER(), table=<01012018>), Column('oi', INTEGER(), table=<01012018>), Column('expiry', TEXT(), table=<01012018>), Column('strike', INTEGER(), table=<01012018>), Column('instrument_type', TEXT(), table=<01012018>), schema=None))?"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Read data from each table using Dask\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Define columns explicitly\n",
        "    columns = [table.c.time, table.c.symbol, table.c.open, table.c.high, table.c.low, table.c.close,\n",
        "               table.c.volume, table.c.oi, table.c.expiry, table.c.strike, table.c.instrument_type]\n",
        "    # Create a select statement with explicit columns\n",
        "    select_stmt = select(*columns).select_from(table).alias()\n",
        "    # Read data into Dask DataFrame\n",
        "    df_dask = dd.read_sql_table(select_stmt, connection_string, index_col='time', npartitions=4)\n",
        "    dfs.append(df_dask)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "TrjTO1WUeJ0m",
        "outputId": "5af5b77c-7ba6-4484-f86e-cdf8a783713a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "`table_name` must be of type str, not <class 'sqlalchemy.sql.selectable.Subquery'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-450da3613106>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mselect_stmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Read data into Dask DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf_dask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_stmt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/sql.py\u001b[0m in \u001b[0;36mread_sql_table\u001b[0;34m(table_name, con, index_col, divisions, npartitions, limits, columns, bytes_per_chunk, head_rows, schema, meta, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    293\u001b[0m             \u001b[0;34m\"`table_name` must be of type str, not \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         )\n",
            "\u001b[0;31mTypeError\u001b[0m: `table_name` must be of type str, not <class 'sqlalchemy.sql.selectable.Subquery'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Read data from each table using Dask\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Define columns explicitly\n",
        "    columns = [table.c.time, table.c.symbol, table.c.open, table.c.high, table.c.low, table.c.close,\n",
        "               table.c.volume, table.c.oi, table.c.expiry, table.c.strike, table.c.instrument_type]\n",
        "    # Create a select statement with explicit columns\n",
        "    select_stmt = select(*columns).select_from(table)\n",
        "    # Execute the select statement\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(select_stmt)\n",
        "        # Convert result to DataFrame\n",
        "        df = dd.from_delayed([result.fetchall()], meta=result._metadata)\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Set the index column\n",
        "merged_df = merged_df.set_index('time')\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "FxyRR311eJyW",
        "outputId": "adb53604-a2dd-400e-dc7d-67296d262846"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Expected Delayed object, got list",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-0cb63d130103>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_stmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Convert result to DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/io.py\u001b[0m in \u001b[0;36mfrom_delayed\u001b[0;34m(dfs, meta, divisions, prefix, verify_meta)\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDelayed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected Delayed object, got %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected Delayed object, got list"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from dask.delayed import delayed\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Read data from each table using Dask\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Define columns explicitly\n",
        "    columns = [table.c.time, table.c.symbol, table.c.open, table.c.high, table.c.low, table.c.close,\n",
        "               table.c.volume, table.c.oi, table.c.expiry, table.c.strike, table.c.instrument_type]\n",
        "    # Create a select statement with explicit columns\n",
        "    select_stmt = select(*columns).select_from(table)\n",
        "    # Execute the select statement\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(select_stmt)\n",
        "        # Convert result to delayed object\n",
        "        delayed_result = delayed(result.fetchall)()\n",
        "        # Convert delayed result to DataFrame\n",
        "        df = dd.from_delayed([delayed_result], meta=result._metadata)\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Set the index column\n",
        "merged_df = merged_df.set_index('time')\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "zpWWqaPXeJwo",
        "outputId": "89bea8ce-4aac-4e08-986c-114ead59fed0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Don't know how to create metadata from <sqlalchemy.engine.cursor.CursorResultMetaData object at 0x7c94c9059700>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/dispatch.py\u001b[0m in \u001b[0;36mmake_meta\u001b[0;34m(x, index, parent_meta)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmake_meta_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \"\"\"\n\u001b[0;32m--> 641\u001b[0;31m         \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/utils.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self, cls)\u001b[0m\n\u001b[1;32m    634\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# recurse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No dispatch for {cls}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: No dispatch for <class 'sqlalchemy.engine.cursor.CursorResultMetaData'>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f9b413a009e7>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdelayed_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Convert delayed result to DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed_result\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/io.py\u001b[0m in \u001b[0;36mfrom_delayed\u001b[0;34m(dfs, meta, divisions, prefix, verify_meta)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_meta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/dispatch.py\u001b[0m in \u001b[0;36mmake_meta\u001b[0;34m(x, index, parent_meta)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;31m# if ``parent_meta`` is not specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_meta_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/backends.py\u001b[0m in \u001b[0;36mmake_meta_object\u001b[0;34m(x, index)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nonempty_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Don't know how to create metadata from {x}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Don't know how to create metadata from <sqlalchemy.engine.cursor.CursorResultMetaData object at 0x7c94c9059700>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from dask.delayed import delayed\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Read data from each table using Dask\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Define columns explicitly\n",
        "    columns = [table.c.time, table.c.symbol, table.c.open, table.c.high, table.c.low, table.c.close,\n",
        "               table.c.volume, table.c.oi, table.c.expiry, table.c.strike, table.c.instrument_type]\n",
        "    # Create a select statement with explicit columns\n",
        "    select_stmt = select(*columns).select_from(table)\n",
        "    # Execute the select statement\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(select_stmt)\n",
        "        # Convert result to delayed object\n",
        "        delayed_result = delayed(result.fetchall)()\n",
        "        # Create Dask metadata manually\n",
        "        meta = {\n",
        "            'time': str(result._metadata.columns['time'].type),\n",
        "            'symbol': str(result._metadata.columns['symbol'].type),\n",
        "            'open': str(result._metadata.columns['open'].type),\n",
        "            'high': str(result._metadata.columns['high'].type),\n",
        "            'low': str(result._metadata.columns['low'].type),\n",
        "            'close': str(result._metadata.columns['close'].type),\n",
        "            'volume': str(result._metadata.columns['volume'].type),\n",
        "            'oi': str(result._metadata.columns['oi'].type),\n",
        "            'expiry': str(result._metadata.columns['expiry'].type),\n",
        "            'strike': str(result._metadata.columns['strike'].type),\n",
        "            'instrument_type': str(result._metadata.columns['instrument_type'].type)\n",
        "        }\n",
        "        # Convert delayed result to DataFrame\n",
        "        df = dd.from_delayed([delayed_result], meta=meta)\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Set the index column\n",
        "merged_df = merged_df.set_index('time')\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Xsw-F2hkeJu9",
        "outputId": "8987ce6e-9002-4bf7-bb76-4726d26d42cb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'CursorResultMetaData' object has no attribute 'columns'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4353cb7d3903>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Create Dask metadata manually\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         meta = {\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0;34m'time'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0;34m'symbol'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;34m'open'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'open'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'CursorResultMetaData' object has no attribute 'columns'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from dask.delayed import delayed\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Read data from each table using Dask\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Define columns explicitly\n",
        "    columns = [table.c.time, table.c.symbol, table.c.open, table.c.high, table.c.low, table.c.close,\n",
        "               table.c.volume, table.c.oi, table.c.expiry, table.c.strike, table.c.instrument_type]\n",
        "    # Create a select statement with explicit columns\n",
        "    select_stmt = select(*columns).select_from(table)\n",
        "    # Execute the select statement\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(select_stmt)\n",
        "        # Convert result to delayed object\n",
        "        delayed_result = delayed(result.fetchall)()\n",
        "        # Create Dask metadata manually\n",
        "        meta = {\n",
        "            'time': 'datetime64[ns]',  # Assuming 'time' column is of datetime type\n",
        "            'symbol': str,  # Assuming 'symbol' column is of string type\n",
        "            'open': float,  # Assuming 'open' column is of float type\n",
        "            'high': float,  # Assuming 'high' column is of float type\n",
        "            'low': float,   # Assuming 'low' column is of float type\n",
        "            'close': float, # Assuming 'close' column is of float type\n",
        "            'volume': int,  # Assuming 'volume' column is of integer type\n",
        "            'oi': int,      # Assuming 'oi' column is of integer type\n",
        "            'expiry': str,  # Assuming 'expiry' column is of string type\n",
        "            'strike': int,  # Assuming 'strike' column is of integer type\n",
        "            'instrument_type': str  # Assuming 'instrument_type' column is of string type\n",
        "        }\n",
        "        # Convert delayed result to DataFrame\n",
        "        df = dd.from_delayed([delayed_result], meta=meta)\n",
        "        dfs.append(df)\n",
        "\n",
        "# Concatenate the dataframes\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Set the index column\n",
        "merged_df = merged_df.set_index('time')\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "xTJ3AkDTeJs9",
        "outputId": "d73ca180-10d4-4e14-d118-1d1e64a6c432"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Metadata mismatch found in `from_delayed`.\n\nExpected partition of type `pandas.core.frame.DataFrame` but got `list`",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-baafcabe0a29>\u001b[0m in \u001b[0;36m<cell line: 57>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m# Set the index column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Print the head of the merged DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/shuffle.py\u001b[0m in \u001b[0;36mset_index\u001b[0;34m(df, index, npartitions, shuffle, compute, drop, upsample, divisions, partition_size, sort, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdivisions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         divisions, mins, maxes, presorted = _calculate_divisions(\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepartition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupsample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/shuffle.py\u001b[0m in \u001b[0;36m_calculate_divisions\u001b[0;34m(df, partition_col, repartition, npartitions, upsample, partition_size, ascending)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mdivisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdivisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# When there are nulls and a column is non-numeric, a TypeError is sometimes raised as a result of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiprocessingPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     results = get_async(\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m                             \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Re-execute locally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                             \u001b[0mraise_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m                     \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cache\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py\u001b[0m in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[0mid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/utils.py\u001b[0m in \u001b[0;36mcheck_meta\u001b[0;34m(x, meta, funcname, numeric_equal)\u001b[0m\n\u001b[1;32m    421\u001b[0m         )\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;34m\"Metadata mismatch found%s.\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;34m\"%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" in `%s`\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfuncname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfuncname\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Metadata mismatch found in `from_delayed`.\n\nExpected partition of type `pandas.core.frame.DataFrame` but got `list`"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "from dask.delayed import delayed\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Function to read each table as a Dask DataFrame\n",
        "def read_table(table_name):\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Define columns explicitly\n",
        "    columns = [table.c.time, table.c.symbol, table.c.open, table.c.high, table.c.low, table.c.close,\n",
        "               table.c.volume, table.c.oi, table.c.expiry, table.c.strike, table.c.instrument_type]\n",
        "    # Create a select statement with explicit columns\n",
        "    select_stmt = select(*columns).select_from(table)\n",
        "    # Execute the select statement and fetch results into a Dask DataFrame\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(select_stmt)\n",
        "        # Convert each row to a delayed object\n",
        "        delayed_results = [delayed(row) for row in result.fetchall()]\n",
        "        # Create Dask metadata manually\n",
        "        meta = {\n",
        "            'time': 'datetime64[ns]',  # Assuming 'time' column is of datetime type\n",
        "            'symbol': str,  # Assuming 'symbol' column is of string type\n",
        "            'open': float,  # Assuming 'open' column is of float type\n",
        "            'high': float,  # Assuming 'high' column is of float type\n",
        "            'low': float,   # Assuming 'low' column is of float type\n",
        "            'close': float, # Assuming 'close' column is of float type\n",
        "            'volume': int,  # Assuming 'volume' column is of integer type\n",
        "            'oi': int,      # Assuming 'oi' column is of integer type\n",
        "            'expiry': str,  # Assuming 'expiry' column is of string type\n",
        "            'strike': int,  # Assuming 'strike' column is of integer type\n",
        "            'instrument_type': str  # Assuming 'instrument_type' column is of string type\n",
        "        }\n",
        "        # Convert delayed results to DataFrame\n",
        "        df = dd.from_delayed(delayed_results, meta=meta)\n",
        "    return df\n",
        "\n",
        "\n",
        "# Read data from each table using Dask and concatenate them\n",
        "dfs = [read_table(table_name) for table_name in relevant_table_names]\n",
        "\n",
        "'''# Check metadata of each DataFrame\n",
        "for i, df in enumerate(dfs):\n",
        "    print(f\"Metadata of DataFrame {i + 1}:\")\n",
        "    print(df.dtypes)  # Print data types of columns'''\n",
        "\n",
        "for i, df in enumerate(dfs):\n",
        "    dfs[i]['symbol'] = df['symbol'].astype('string')\n",
        "    dfs[i]['expiry'] = df['expiry'].astype('string')\n",
        "    dfs[i]['instrument_type'] = df['instrument_type'].astype('string')\n",
        "\n",
        "# Concatenate DataFrames\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())"
      ],
      "metadata": {
        "id": "r-SgoYzh5nf0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine, MetaData, Table, select\n",
        "from dask.delayed import delayed\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create an SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create an SQLAlchemy MetaData object\n",
        "metadata = MetaData()\n",
        "\n",
        "# Reflect all tables from the database\n",
        "metadata.reflect(bind=engine)\n",
        "\n",
        "# Filter relevant tables\n",
        "relevant_table_names = [table_name for table_name in metadata.tables.keys() if int(table_name[-4:]) > 2017]\n",
        "\n",
        "# Function to read each table as a Dask DataFrame\n",
        "def read_table(table_name):\n",
        "    # Reflect the table\n",
        "    table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
        "    # Define columns explicitly\n",
        "    columns = [table.c.time, table.c.symbol, table.c.open, table.c.high, table.c.low, table.c.close,\n",
        "               table.c.volume, table.c.oi, table.c.expiry, table.c.strike, table.c.instrument_type]\n",
        "    # Create a select statement with explicit columns\n",
        "    select_stmt = select(*columns).select_from(table)\n",
        "    # Execute the select statement and fetch results\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(select_stmt)\n",
        "        # Get metadata\n",
        "        meta = {col.name: col.type.python_type for col in result.cursor.description}\n",
        "        # Convert each row to a delayed DataFrame\n",
        "        delayed_dfs = [dd.from_delayed([delayed(row)] * len(columns), meta=meta, columns=columns) for row in result.fetchall()]\n",
        "    return delayed_dfs\n",
        "\n",
        "# Read data from each table using Dask and concatenate them\n",
        "dfs = [df for table_name in relevant_table_names for df in read_table(table_name)]\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Print the head of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "oXsJqyReisF2",
        "outputId": "49004894-a598-4cbb-824a-ae6e9b8143e7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'tuple' object has no attribute 'name'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-fcd4df96c672>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Read data from each table using Dask and concatenate them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_table_names\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-fcd4df96c672>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# Read data from each table using Dask and concatenate them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_table_names\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mmerged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-fcd4df96c672>\u001b[0m in \u001b[0;36mread_table\u001b[0;34m(table_name)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_stmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Get metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_type\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Convert each row to a delayed DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdelayed_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-fcd4df96c672>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselect_stmt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# Get metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_type\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Convert each row to a delayed DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mdelayed_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_delayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h_uhGqtCir60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jr5Z3aPOir4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "V5Nv4MiveLqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "sql_engine = create_engine(connection_string)\n",
        "\n",
        "tables_query = '''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%';\n",
        "'''\n",
        "import pandas as pd\n",
        "tables_df = pd.read_sql_query(tables_query, sql_engine)\n",
        "\n",
        "relevant_table_names = tables_df[tables_df['name'].str[-4:].astype(int) > 2017]['name'].tolist()\n",
        "\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    sql_query = f\"SELECT *, CAST(time AS DATETIME) AS time FROM {table_name};\"\n",
        "    df_dask = dd.read_sql_query(sql_query, sql_engine, index_col='time', npartitions=4)\n",
        "    dfs.append(df_dask)\n",
        "\n",
        "merged_df = dd.concat(dfs)\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "_szmWQy_5ndb",
        "outputId": "9e4f1b3d-6a85-4b64-ed45-c8b9d21ee59d"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'con' must be of type str, not <class 'sqlalchemy.engine.base.Engine'>Note: Dask does not support SQLAlchemy connectables here",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-c3db696812bd>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_table_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msql_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"SELECT *, CAST(time AS DATETIME) AS time FROM {table_name};\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdf_dask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, divisions, npartitions, limits, bytes_per_chunk, head_rows, meta, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;34m\"'con' must be of type str, not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'con' must be of type str, not <class 'sqlalchemy.engine.base.Engine'>Note: Dask does not support SQLAlchemy connectables here"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "tables_query = '''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%';\n",
        "'''\n",
        "import pandas as pd\n",
        "tables_df = pd.read_sql_query(tables_query, connection_string)\n",
        "\n",
        "relevant_table_names = tables_df[tables_df['name'].str[-4:].astype(int) > 2017]['name'].tolist()\n",
        "\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    sql_query = f\"SELECT *, CAST(time AS DATETIME) AS time FROM {table_name};\"\n",
        "    df_dask = dd.read_sql_query(sql_query, connection_string, index_col='time', npartitions=4)\n",
        "    dfs.append(df_dask)\n",
        "\n",
        "merged_df = dd.concat(dfs)\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "NwH7I9ET5nmQ",
        "outputId": "fc63533d-9b94-4b45-fcfa-8cb3a2666c91"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'limit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-7c7cdc8185bc>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Read data into Dask DataFrame using connection string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf_dask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, divisions, npartitions, limits, bytes_per_chunk, head_rows, meta, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead_rows\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# derive metadata from first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'limit'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "sql_engine = create_engine(connection_string)\n",
        "\n",
        "# Execute the query to get relevant table names\n",
        "tables_query = '''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%';\n",
        "'''\n",
        "tables_df = pd.read_sql_query(tables_query, sql_engine)\n",
        "\n",
        "# Filter relevant table names based on the last 4 characters (assuming they represent years)\n",
        "relevant_table_names = tables_df[tables_df['name'].str[-4:].astype(int) > 2017]['name'].tolist()\n",
        "\n",
        "# Define a list to store Dask DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through relevant table names\n",
        "for table_name in relevant_table_names:\n",
        "    # Construct SQL query to select all columns and cast 'time' as DATETIME\n",
        "    sql_query = f\"SELECT *, CAST(time AS DATETIME) AS time FROM `{table_name}`;\"\n",
        "\n",
        "    # Read data into a Pandas DataFrame\n",
        "    df_pandas = pd.read_sql_query(sql_query, sql_engine, index_col='time')\n",
        "\n",
        "    # Convert Pandas DataFrame to Dask DataFrame\n",
        "    df_dask = dd.from_pandas(df_pandas, npartitions=4)\n",
        "\n",
        "    # Append Dask DataFrame to the list\n",
        "    dfs.append(df_dask)\n",
        "\n",
        "# Concatenate Dask DataFrames into one\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Display the first few rows of the merged Dask DataFrame\n",
        "print(merged_df.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "8tAT4BQT5nZ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "sql_engine = create_engine(connection_string)\n",
        "\n",
        "# Execute the query to get relevant table names\n",
        "tables_query = '''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%';\n",
        "'''\n",
        "tables_df = pd.read_sql_query(tables_query, sql_engine)\n",
        "\n",
        "# Filter relevant table names based on the last 4 characters (assuming they represent years)\n",
        "relevant_table_names = tables_df[tables_df['name'].str[-4:].astype(int) > 2017]['name'].tolist()\n",
        "\n",
        "# Define a list to store Dask DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Loop through relevant table names\n",
        "for table_name in relevant_table_names:\n",
        "    # Construct SQL query to select all columns and cast 'time' as DATETIME\n",
        "    sql_query = f\"SELECT *, CAST(time AS DATETIME) AS time FROM `{table_name}`;\"\n",
        "\n",
        "    # Read data into a Dask DataFrame\n",
        "    df_dask = dd.read_sql_query(sql_query, sql_engine, index_col='time', npartitions=4)\n",
        "\n",
        "    # Append Dask DataFrame to the list\n",
        "    dfs.append(df_dask)\n",
        "\n",
        "# Concatenate Dask DataFrames into one\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Display the first few rows of the merged Dask DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "l4Nei1g9QElc",
        "outputId": "3fe2d232-3756-4dae-bc26-a5faa6d392f8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'con' must be of type str, not <class 'sqlalchemy.engine.base.Engine'>Note: Dask does not support SQLAlchemy connectables here",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9c20be986d08>\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Read data into a Dask DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdf_dask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Append Dask DataFrame to the list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, divisions, npartitions, limits, bytes_per_chunk, head_rows, meta, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;34m\"'con' must be of type str, not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'con' must be of type str, not <class 'sqlalchemy.engine.base.Engine'>Note: Dask does not support SQLAlchemy connectables here"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WZ8tQlldQEjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mGFPMMYBQEed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RtzBHuV_QERc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F5dy3YypQENL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K3DLypAyQEK_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i6NhmBj0QEI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Xgu_ONLQEGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6OKWRgjIQEEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXt55k5LQEBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import pandas as pd\n",
        "from sqlalchemy import text\n",
        "\n",
        "# Define the SQL query to select data\n",
        "query = text(\"SELECT * FROM '02012018';\")\n",
        "\n",
        "# Read the data into a Pandas DataFrame\n",
        "df_pandas = pd.read_sql_query(query, connection_string)\n",
        "\n",
        "# Check the data types of the index column\n",
        "print(df_pandas.dtypes)\n",
        "\n",
        "# Convert the 'time' column to datetime if it's not already in that format\n",
        "df_pandas['time'] = pd.to_datetime(df_pandas['time'])\n",
        "\n",
        "# Convert the Pandas DataFrame to a Dask DataFrame\n",
        "df_dask = dd.from_pandas(df_pandas, npartitions=1)\n",
        "\n",
        "# Display the first few rows of the Dask DataFrame\n",
        "df_dask.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "clgxuvbhlxYg",
        "outputId": "c527dd47-d8c5-419d-f539-fc838b60d606"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time                object\n",
            "symbol              object\n",
            "open               float64\n",
            "high               float64\n",
            "low                float64\n",
            "close              float64\n",
            "volume               int64\n",
            "oi                   int64\n",
            "expiry              object\n",
            "strike               int64\n",
            "instrument_type     object\n",
            "dtype: object\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-334f86d3de1a>:15: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_pandas['time'] = pd.to_datetime(df_pandas['time'])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 time                   symbol  open  high   low  close  \\\n",
              "0 2024-05-03 09:29:00  BANKNIFTY04JAN1823300PE  0.50  2.00  0.50   0.50   \n",
              "1 2024-05-03 09:30:00  BANKNIFTY04JAN1823300PE  2.00  2.00  2.00   2.00   \n",
              "2 2024-05-03 09:31:00  BANKNIFTY04JAN1823300PE  2.00  2.00  2.00   2.00   \n",
              "3 2024-05-03 09:34:00  BANKNIFTY04JAN1823300PE  0.15  0.15  0.15   0.15   \n",
              "4 2024-05-03 09:50:00  BANKNIFTY04JAN1823300PE  0.35  0.35  0.35   0.35   \n",
              "\n",
              "   volume    oi      expiry  strike instrument_type  \n",
              "0      80  5800  04-01-2018   23300              PE  \n",
              "1      80  5800  04-01-2018   23300              PE  \n",
              "2      80  5800  04-01-2018   23300              PE  \n",
              "3     240  5800  04-01-2018   23300              PE  \n",
              "4      40  5800  04-01-2018   23300              PE  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afe65e80-6bd8-449c-b651-acb4ada2aa6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>time</th>\n",
              "      <th>symbol</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>oi</th>\n",
              "      <th>expiry</th>\n",
              "      <th>strike</th>\n",
              "      <th>instrument_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2024-05-03 09:29:00</td>\n",
              "      <td>BANKNIFTY04JAN1823300PE</td>\n",
              "      <td>0.50</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.50</td>\n",
              "      <td>80</td>\n",
              "      <td>5800</td>\n",
              "      <td>04-01-2018</td>\n",
              "      <td>23300</td>\n",
              "      <td>PE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2024-05-03 09:30:00</td>\n",
              "      <td>BANKNIFTY04JAN1823300PE</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>80</td>\n",
              "      <td>5800</td>\n",
              "      <td>04-01-2018</td>\n",
              "      <td>23300</td>\n",
              "      <td>PE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2024-05-03 09:31:00</td>\n",
              "      <td>BANKNIFTY04JAN1823300PE</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>2.00</td>\n",
              "      <td>80</td>\n",
              "      <td>5800</td>\n",
              "      <td>04-01-2018</td>\n",
              "      <td>23300</td>\n",
              "      <td>PE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2024-05-03 09:34:00</td>\n",
              "      <td>BANKNIFTY04JAN1823300PE</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.15</td>\n",
              "      <td>240</td>\n",
              "      <td>5800</td>\n",
              "      <td>04-01-2018</td>\n",
              "      <td>23300</td>\n",
              "      <td>PE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2024-05-03 09:50:00</td>\n",
              "      <td>BANKNIFTY04JAN1823300PE</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.35</td>\n",
              "      <td>40</td>\n",
              "      <td>5800</td>\n",
              "      <td>04-01-2018</td>\n",
              "      <td>23300</td>\n",
              "      <td>PE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afe65e80-6bd8-449c-b651-acb4ada2aa6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afe65e80-6bd8-449c-b651-acb4ada2aa6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afe65e80-6bd8-449c-b651-acb4ada2aa6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6dff21ad-f852-4982-a43f-dd35afa0bbc1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6dff21ad-f852-4982-a43f-dd35afa0bbc1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6dff21ad-f852-4982-a43f-dd35afa0bbc1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_dask\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"time\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2024-05-03 09:29:00\",\n        \"max\": \"2024-05-03 09:50:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2024-05-03 09:30:00\",\n          \"2024-05-03 09:50:00\",\n          \"2024-05-03 09:31:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"symbol\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"BANKNIFTY04JAN1823300PE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9212762886344139,\n        \"min\": 0.15,\n        \"max\": 2.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9611191393370543,\n        \"min\": 0.15,\n        \"max\": 2.0,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9212762886344139,\n        \"min\": 0.15,\n        \"max\": 2.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9212762886344139,\n        \"min\": 0.15,\n        \"max\": 2.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 77,\n        \"min\": 40,\n        \"max\": 240,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          80\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"oi\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5800,\n        \"max\": 5800,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5800\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expiry\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"04-01-2018\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"strike\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 23300,\n        \"max\": 23300,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          23300\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"instrument_type\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"PE\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J2i7--mMQhLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BDHq_vptQhIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QpCCAIMVQhF-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNuFEGOuL2s_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "opUYXWiJL2qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "import os\n",
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Define the connection string\n",
        "connection_string = 'sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db'\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Define the SQL query to retrieve table names\n",
        "tables_query = text('''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%';\n",
        "''')\n",
        "\n",
        "# Retrieve table names\n",
        "with engine.connect() as connection:\n",
        "    tables = connection.execute(tables_query)\n",
        "    table_names = [table[0] for table in tables]\n",
        "\n",
        "# Define the folder to store the CSV files\n",
        "csv_folder = '/content/sample_data/Bank_Nifty_csv'\n",
        "os.makedirs(csv_folder, exist_ok=True)\n",
        "\n",
        "# Function to export each table to CSV\n",
        "def export_table_to_csv(table_name):\n",
        "    query = f\"SELECT * FROM {table_name};\"\n",
        "    # Read data from the database using Dask\n",
        "    df = dd.read_sql_query(query, connection_string, index_col='time')\n",
        "    df = df.set_index('time')\n",
        "    # Write the dataframe to a CSV file\n",
        "    df.to_csv(os.path.join(csv_folder, f'{table_name}.csv'))\n",
        "\n",
        "for table_name in table_names:\n",
        "    export_table_to_csv(table_name)\n",
        "\n",
        "csv_files = [os.path.join(csv_folder, f'{table_name}.csv') for table_name in table_names]\n",
        "\n",
        "\n",
        "def read_csv(file):\n",
        "    return dd.read_csv(file)\n",
        "\n",
        "dfs = [dask.delayed(read_csv)(file) for file in csv_files]\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "merged_df = merged_df.compute()\n"
      ],
      "metadata": {
        "id": "qL3xt5TINHbi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "228e942f-c313-4407-9b5d-9f351e9172ee"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'limit'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-894d5251e4f5>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mexport_table_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mcsv_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{table_name}.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtable_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-894d5251e4f5>\u001b[0m in \u001b[0;36mexport_table_to_csv\u001b[0;34m(table_name)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"SELECT * FROM {table_name};\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Read data from the database using Dask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# Write the dataframe to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, divisions, npartitions, limits, bytes_per_chunk, head_rows, meta, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhead_rows\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# derive metadata from first few rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhead_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'limit'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "\n",
        "# SQLite database path\n",
        "db_path = \"/content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create SQLAlchemy engine\n",
        "sql_engine = create_engine(f\"sqlite:///{db_path}\")\n",
        "\n",
        "# Define the SQL query to get relevant table names\n",
        "tables_query = '''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%' AND CAST(substr(name, -4) AS INT) > 2017;\n",
        "'''\n",
        "\n",
        "# Read table names from SQLite database\n",
        "relevant_table_names = pd.read_sql_query(tables_query, sql_engine)['name'].tolist()\n",
        "\n",
        "# Define the folder to store the CSV files\n",
        "csv_folder = '/content/sample_data/Bank_Nifty_csv'\n",
        "os.makedirs(csv_folder, exist_ok=True)\n",
        "\n",
        "# Function to export each table to CSV\n",
        "def export_table_to_csv(table_name):\n",
        "    query = f\"SELECT * FROM {table_name};\"\n",
        "    # Read data from the database using Dask\n",
        "    df = dd.read_sql_query(query, sql_engine)\n",
        "    # Write the dataframe to a CSV file\n",
        "    df.to_csv(os.path.join(csv_folder, f'{table_name}.csv'), index=False)\n",
        "\n",
        "# Export each relevant table to CSV\n",
        "for table_name in relevant_table_names:\n",
        "    export_table_to_csv(table_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "O4CD2iGKW6zK",
        "outputId": "44975dc5-34a8-4f1b-ea3e-e3ddb3f46868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "read_sql_query() missing 1 required positional argument: 'index_col'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-7defe9d4969c>\u001b[0m in \u001b[0;36m<cell line: 35>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;31m# Export each relevant table to CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrelevant_table_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mexport_table_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-38-7defe9d4969c>\u001b[0m in \u001b[0;36mexport_table_to_csv\u001b[0;34m(table_name)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"SELECT * FROM {table_name};\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m# Read data from the database using Dask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_engine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Write the dataframe to a CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsv_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{table_name}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: read_sql_query() missing 1 required positional argument: 'index_col'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# Define the path to the SQLite database file\n",
        "db_path = \"/content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "\n",
        "# Create a SQLAlchemy engine\n",
        "engine = create_engine(f\"sqlite:///{db_path}\")\n",
        "\n",
        "# Define the SQL query to select data\n",
        "chunk_size = 100\n",
        "relevant_table_names=relevant_table_names\n",
        "\n",
        "# Initialize an empty list to store data chunks\n",
        "all_chunks = []\n",
        "\n",
        "# Iterate over each table in relevant_table_names\n",
        "for table_name in relevant_table_names:\n",
        "    query = f\"SELECT * FROM `{table_name}`;\"  # Enclose table name in backticks\n",
        "    data_chunks = pd.read_sql_query(query, engine, chunksize=chunk_size)\n",
        "\n",
        "    # Append each chunk to the list of chunks\n",
        "    for chunk in data_chunks:\n",
        "        all_chunks.append(chunk)\n",
        "\n",
        "# Concatenate all chunks into a single DataFrame\n",
        "combined_df = pd.concat(all_chunks, ignore_index=True)\n",
        "\n",
        "# Display the combined DataFrame\n",
        "print(\"Combined DataFrame:\")\n",
        "display(combined_df.head())\n"
      ],
      "metadata": {
        "id": "jn6TwEcsddqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yvPt6b3yb7fG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ja31kS3Tp7YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aVb71OqSp7Vu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "from dask import delayed, compute\n",
        "\n",
        "# Define the SQLAlchemy engine\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Create a list to store delayed tasks for reading tables\n",
        "delayed_dfs = []\n",
        "\n",
        "# Define a function to read each table and convert to Dask DataFrame\n",
        "def read_table_to_dask(table_name):\n",
        "    # Read the SQL table into a Pandas DataFrame\n",
        "    df_pd = pd.read_sql_table(table_name, engine)\n",
        "\n",
        "    # Convert the 'time' column to datetime with specified format\n",
        "    df_pd['time'] = pd.to_datetime(df_pd['time'], format='%H:%M:%S')\n",
        "\n",
        "    # Convert the Pandas DataFrame to a Dask DataFrame\n",
        "    df_dask = dd.from_pandas(df_pd, npartitions=4)  # You can adjust the number of partitions as needed\n",
        "\n",
        "    # Set the 'time' column as the index\n",
        "    df_dask = df_dask.set_index('time')\n",
        "\n",
        "    return df_dask\n",
        "\n",
        "# Create delayed tasks for reading each table\n",
        "for table_name in relevant_table_names:\n",
        "    delayed_df = delayed(read_table_to_dask)(table_name)\n",
        "    delayed_dfs.append(delayed_df)\n",
        "\n",
        "# Compute the delayed tasks in parallel\n",
        "dfs = compute(*delayed_dfs)\n",
        "\n",
        "# Concatenate all the Dask DataFrames into a single DataFrame\n",
        "merged_df = dd.concat(dfs)\n",
        "\n",
        "# Display the first few rows of the merged DataFrame\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "UFkbTeeGqPVb",
        "outputId": "79b24feb-8e7c-4e2a-9269-fa0c8ca32a41"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-9961d8736377>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Compute the delayed tasks in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdelayed_dfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Concatenate all the Dask DataFrames into a single DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0mpostcomputes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dask_postcompute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    667\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiprocessingPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m     results = get_async(\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_max_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"waiting\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ready\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"running\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m                 \u001b[0mfire_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    501\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m                         \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2qc_f7qnrxjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MK504WeZsIXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import dask.dataframe as dd\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "sql_engine = create_engine(\"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\")\n",
        "connection_string = \"sqlite://///content/gdrive/MyDrive/big_file/BANKNIFTY_OPT.db\"\n",
        "tables_query = '''\n",
        "    SELECT name\n",
        "    FROM sqlite_master\n",
        "    WHERE type='table' AND name NOT LIKE 'sqlite_%';\n",
        "'''\n",
        "\n",
        "# Connect to the database\n",
        "conn = sql_engine.connect()\n",
        "\n",
        "# Execute the query to get relevant table names\n",
        "relevant_table_names =relevant_table_names\n",
        "relevant_table_names = [table[0] for table in relevant_table_names]\n",
        "\n",
        "dfs = []\n",
        "for table_name in relevant_table_names:\n",
        "    # Convert SQLAlchemy engine to connection string\n",
        "    sql_query = f\"SELECT *, CAST(time AS DATETIME) AS time FROM {table_name};\"\n",
        "    df_dask = dd.read_sql_query(sql_query, sql_engine, index_col='time', npartitions=4)\n",
        "    dfs.append(df_dask)\n",
        "\n",
        "merged_df = dd.concat(dfs)\n",
        "print(merged_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "tgCzNEXhyFaI",
        "outputId": "0a2f0e1d-b0e0-46df-aad5-610bbbb61b35"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'con' must be of type str, not <class 'sqlalchemy.engine.base.Engine'>Note: Dask does not support SQLAlchemy connectables here",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-09858947f737>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# Convert SQLAlchemy engine to connection string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0msql_query\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"SELECT *, CAST(time AS DATETIME) AS time FROM {table_name};\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdf_dask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msql_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpartitions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_dask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, divisions, npartitions, limits, bytes_per_chunk, head_rows, meta, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0;34m\"'con' must be of type str, not \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'con' must be of type str, not <class 'sqlalchemy.engine.base.Engine'>Note: Dask does not support SQLAlchemy connectables here"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oi_10Hq58CaJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}